# Clinical Assist API Configuration
# Copy this file to .env and update with your values

# General Settings
APP_ENV=dev
APP_VERSION=0.0.1
APP_PORT=8000
APP_ALLOWED_ORIGINS=*
APP_MAX_UPLOAD_SIZE_MB=100
APP_DEFAULT_REQUEST_TIMEOUT_S=30
APP_LOG_LEVEL=INFO

# Speech-to-Text Configuration
# NOTE: The AI Foundry (AIServices) resource provides Speech Services capabilities
# Use STT_BACKEND=azure to use the Azure AI Services Speech-to-Text
STT_BACKEND=azure

# Azure Speech Service (uses AI Foundry AIServices resource)
# NOTE: These will be auto-populated by 'make generate-env' from Terraform outputs
# IMPORTANT: STT_AZURE_SPEECH_RESOURCE_NAME must be the custom subdomain, not the resource name
# Example: capupskilling-dev-sdc (not ai-cap-upskilling-dev-sdc)
STT_AZURE_SPEECH_RESOURCE_NAME=
STT_AZURE_SPEECH_REGION=swedencentral
STT_MAX_FILE_SIZE_MB=100
STT_MAX_DURATION_MINUTES=120

# Alternative: Azure OpenAI Whisper (not currently deployed)
STT_WHISPER_AZURE_OPENAI_ENDPOINT=https://your-openai.openai.azure.com/
STT_WHISPER_API_VERSION=2024-02-01

# Search & Image Extraction
# NOTE: consider these placeholders - feel free to adapt as the actual service is written & evolves!
SEARCH_BACKEND=bing
SEARCH_CONTENT_SAFETY_BACKEND=azure
SEARCH_BING_ENDPOINT=https://api.cognitive.microsoft.com/bing/v7.0/search

# Bing Custom Search (for medical domain search)
# NOTE: These will be auto-populated by 'make generate-env' from Terraform outputs
SEARCH_BING_CUSTOM_CONNECTION_NAME=
SEARCH_BING_CUSTOM_INSTANCE_NAME=

AZURE_CONTENT_SAFETY_ENDPOINT=https://******* 


# FHIR Configuration - HAPI FHIR API Integration
# Optional: Base URL for HAPI FHIR API server (required only for charts feature)
FHIR_BASE_URL=http://localhost:8080/fhir
# Optional: Bearer token for FHIR API authentication (if required)
# FHIR_TOKEN=your-bearer-token-here
# Optional: Request timeout in seconds (default: 30)
FHIR_TIMEOUT_S=30

# FHIR Chart Storage Configuration (to be implemented in backend)
# NOTE: consider these placeholders - feel free to adapt as the actual service is written & evolves!
# Storage modes: memory (base64 in response), temp (workspace temp dir), secure (custom dir)
FHIR_CHART_STORAGE=temp
# Required for secure mode - path to PHI-compliant storage directory
FHIR_CHART_SECURE_DIR=/path/to/secure/charts
# Auto-cleanup after N hours (PHI security)
FHIR_CHART_RETENTION_HOURS=24

# Azure OpenAI / AI Foundry for LLM
# NOTE: These will be auto-populated by 'make generate-env' from Terraform outputs
AZURE_OPENAI_ENDPOINT=https://your-openai.openai.azure.com/
AZURE_OPENAI_DEPLOYMENT=your-gpt4-deployment
AZURE_OPENAI_API_VERSION=2024-02-01

# AI Foundry Configuration (auto-populated from Terraform)
AZURE_AI_FOUNDRY_ENDPOINT=
AZURE_AI_FOUNDRY_DEPLOYMENT=
AZURE_AI_FOUNDRY_API_KEY=
AZURE_AI_FOUNDRY_API_VERSION=2024-02-01
AZURE_AI_FOUNDRY_PROJECT_NAME=

# Azure AI Agent Framework (required by agent_framework_azure_ai)
# NOTE: These will be auto-populated by 'make generate-env' from Terraform outputs
# The agent framework library requires these exact environment variable names
AZURE_AI_PROJECT_ENDPOINT=
AZURE_AI_MODEL_DEPLOYMENT_NAME=

# ICD-10 Automatic Coding Configuration
# NOTE: These will be auto-populated by 'make generate-env' from Terraform outputs
ICD_AZURE_SEARCH_ENDPOINT=https://your-search.search.windows.net
ICD_AZURE_SEARCH_INDEX_NAME=icd10-codes
ICD_AZURE_SEARCH_ADMIN_KEY=  # Optional: uses RBAC if not provided
ICD_AZURE_OPENAI_EMBEDDING_DEPLOYMENT=text-embedding-3-large
ICD_MAX_CANDIDATES=50
ICD_MIN_CONFIDENCE=0.4
ICD_MAX_OUTPUT_CODES=20
ICD_CODES_CSV_PATH=src/backend/service/icd_coding_2/icd_dataset/icd10cm_codes_full.csv

# Security Configuration (for production)
JWT_ISSUER=https://your-auth-provider.com/
JWT_AUDIENCE=clinical-assist-api
JWT_JWKS_URL=https://your-auth-provider.com/.well-known/jwks.json

# Azure Application Insights
# Format: InstrumentationKey=...;IngestionEndpoint=...;LiveEndpoint=...
APPLICATIONINSIGHTS_CONNECTION_STRING=

# Telemetry Sampling & Collection
TELEMETRY_ENABLED=true
TELEMETRY_SAMPLING_RATE=1.0

# OpenTelemetry GenAI Instrumentation
# Set to true to capture LLM message content in traces (WARNING: May capture PII/PHI if enabled)
# References:
# - https://learn.microsoft.com/en-us/azure/ai-foundry/how-to/develop/trace-application
# - https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/ai/azure-ai-inference#tracing
# - https://pypi.org/project/opentelemetry-instrumentation-openai/
OTEL_INSTRUMENTATION_GENAI_CAPTURE_MESSAGE_CONTENT=false

# Content Logging (WARNING: May capture PII if enabled)
TELEMETRY_LOG_REQUESTS=false
TELEMETRY_LOG_RESPONSES=false
TELEMETRY_LOG_LEVEL=minimal
TELEMETRY_MASK_PII=true
TELEMETRY_PRESIDIO_MASKING=true

# Token Usage Tracking
TELEMETRY_TRACK_TOKEN_USAGE=true

# Performance Thresholds
TELEMETRY_LATENCY_THRESHOLD_MS=3000
TELEMETRY_ERROR_RATE_THRESHOLD=0.05
